https://blog.csdn.net/kidgin7439/category_11998768.html  和知乎同名的

NVIDIA NCCL 源码学习（十）- 多机间ncclSend和ncclRecv的过程
https://blog.csdn.net/KIDGIN7439/article/details/130936177
回忆一下单机的执行流程，用户执行ncclSend之后通过ncclEnqueueCheck将sendbuff，sendbytes，peer等信息保存到了comm->p2plist中；
然后执行ncclGroupEnd，如果发现channel没有建立到peer的链接则先建链，
然后根据p2plist执行scheduleSendRecv(ncclSaveKernel)将信息保存到channel->collectives，
然后再启动kernel，kernel会遍历channel->collectives执行send和recv。然后我们看下多机的流程是怎样的。
==
下边是之前第八节中关于flush的介绍
gpuFlush也对应一个qp，不过这个qp是local的，即他的对端qp就是自己，
当开启gdr之后，每次接收数据后都需要执行一下flush，
其实是一个rdma read操作，
使用网卡读一下接收到的数据的第一个int到hostMem。
官方issue里解释说当通过gdr接收数据完成，产生wc到cpu的时候，
接收的数据并不一定在gpu端可以读到，
这个时候需要在cpu端执行一下读取。

关于执行读取为什么能够保序后来咨询kkndyu大佬了解到，PCIe设备中有Transaction Ordering的概念，在同一个PCIe控制器中默认Read Request不会超过Posted Request，如下图col2
005-006
最后总结下多机通信的整体流程
    通信由kernel和proxy线程协调完成，send端kernel负责将数据从input搬运到buf，proxy线程负责将buf中数据通过网络发送给recv端
    kernel和proxy间通过队列实现生产者消费者模式
    send端通过rdma send发送数据，和recv端通过队列实现生产者消费者模式，队列位于send端，recv端每次下发一个wr到rq之后会执行rdma write通知send端




NVIDIA NCCL 源码学习（九）- 单机内ncclSend和ncclRecv的过程
https://blog.csdn.net/KIDGIN7439/article/details/128326053
上节介绍了通信链路的建立过程，本节介绍下单机内部ncclSend和ncclRecv的运行过程。
单机内的通信都是通过kernel来进行的，所以整个通信的过程可以分为两步，第一步是准备kernel相关的参数，第二步是实际执行kernel的过程。
为方便表述，下边例子不加说明的话均为单机单线程两卡的场景，测试用例如下。
#include <stdio.h>
#include "cuda_runtime.h"
#include "nccl.h"
#include <unistd.h>
#include <stdint.h>

#define CUDACHECK(cmd) do {                         \
    cudaError_t e = cmd;                              \
    if( e != cudaSuccess ) {                          \
        printf("Failed: Cuda error %s:%d '%s'\n",             \
                __FILE__,__LINE__,cudaGetErrorString(e));   \
        exit(EXIT_FAILURE);                             \
    }                                                 \
} while(0)


#define NCCLCHECK(cmd) do {                         \
    ncclResult_t r = cmd;                             \
    if (r!= ncclSuccess) {                            \
        printf("Failed, NCCL error %s:%d '%s'\n",             \
                __FILE__,__LINE__,ncclGetErrorString(r));   \
        exit(EXIT_FAILURE);                             \
    }                                                 \
} while(0)


int main(int argc, char* argv[])
{
    //each process is using two GPUs
    int nDev = 2;
    int nRanks = nDev;

    int chunk = 1024*1024;
    int size = nDev * chunk;

    float** sendbuff = (float**)malloc(nDev * sizeof(float*));
    float** recvbuff = (float**)malloc(nDev * sizeof(float*));
    cudaStream_t* s = (cudaStream_t*)malloc(sizeof(cudaStream_t)*nDev);

    //picking GPUs based on localRank
    for (int i = 0; i < nDev; ++i) {
        CUDACHECK(cudaSetDevice(i));
        CUDACHECK(cudaMalloc(sendbuff + i, size * sizeof(float)));
        CUDACHECK(cudaMalloc(recvbuff + i, size * sizeof(float)));
        CUDACHECK(cudaMemset(sendbuff[i], 1, size * sizeof(float)));
        CUDACHECK(cudaMemset(recvbuff[i], 0, size * sizeof(float)));
        CUDACHECK(cudaStreamCreate(s+i));
    }

    ncclUniqueId id;
    ncclComm_t comms[nDev];
    //generating NCCL unique ID at one process and broadcasting it to all
    ncclGetUniqueId(&id);

    //initializing NCCL, group API is required around ncclCommInitRank as it is
    //called across multiple GPUs in each thread/process
    NCCLCHECK(ncclGroupStart());
    for (int i=0; i<nDev; i++) {
        CUDACHECK(cudaSetDevice(i));
        NCCLCHECK(ncclCommInitRank(comms+i, nRanks, id, i));
    }
    NCCLCHECK(ncclGroupEnd());

    //calling NCCL communication API. Group API is required when using
    //multiple devices per thread/process
    NCCLCHECK(ncclGroupStart());
    for (int i=0; i<nDev; i++) {
        for (int j = 0; j < nDev; j++) {
                NCCLCHECK(ncclSend((const void*)(sendbuff[i] + j * chunk), chunk, ncclFloat, j, comms[i], s[i]));
                NCCLCHECK(ncclRecv((void*)(recvbuff[i] + j * chunk), chunk, ncclFloat, j, comms[i], s[i]));
        }
    }
    NCCLCHECK(ncclGroupEnd());

    //synchronizing on CUDA stream to complete NCCL communication
    for (int i=0; i<nDev; i++)
        CUDACHECK(cudaStreamSynchronize(s[i]));

    //freeing device memory
    for (int i=0; i<nDev; i++) {
        CUDACHECK(cudaFree(sendbuff[i]));
        CUDACHECK(cudaFree(recvbuff[i]));
    }

    //finalizing NCCL
    for (int i=0; i<nDev; i++) {
        ncclCommDestroy(comms[i]);
    }

    return 0;
}
通信参数准备
先看下通信参数准备的过程，陷入细节之前我们先看下整体样貌。
004-001.png
最下边send0和recv0表示用户为rank0准备的数据buffer


yk===
5,6,7,8可能需要结合具体硬件来理解！！！！


NVIDIA NCCL 源码学习（八）- 数据通信链路transport的建立
https://blog.csdn.net/kidgin7439/article/details/126953432
上节以ringGraph为例介绍了机器间channel的连接过程，现在环里每个rank都知道了从哪个rank接收数据以及将数据发送给哪个rank，本节具体介绍下P2P和rdma NET场景下数据通信链路的建立过程。
上节说到nccl通过ncclTransportP2pSetup完成了数据通信链路的建立，还是以上节两机十六卡的环为例：
第一台机器的环：
graph->intra: GPU/0 GPU/7 GPU/6 GPU/3 GPU/2 GPU/5 GPU/4 GPU/1
graph->inter: NET/0 NET/0
第二台机器的环：
graph->intra: GPU/10 GPU/9 GPU/8 GPU/13 GPU/12 GPU/15 GPU/14 GPU/11
graph->inter: NET/0 NET/0
===============
最后简单总结下，建链的过程都是以下过程：
接收端 执行recv setup，创建buffer等，将相关信息记录到connectIndo，启动一个监听socket，ip port同样记录到connectInfo，通过bootstrap发送connectInfo到 发送端。
发送端 执行send setup，创建buffer等，将相关信息记录到connectInfo，然后发送给 接收端。这一步rdma场景没有用到connectInfo。
发送端 接受到步骤1中 接收端 的信息，然后建立 发送端 到 接收端 的链接，p2p场景的话只是简单记录对端buffer，rdma场景的话需要初始化qp到INIT状态。
接收端 接受到步骤2中send发送的信息，然后建立 接收端 到 发送端 的链接，p2p场景还是记录对端buffer，rdma场景需要初始化qp到RTS状态，将本端的qp信息发送回对端。
如果rdma场景的话，发送端 还需接收对端的qp状态初始化本端的qp到RTS状态。

NVIDIA NCCL 源码学习（七）- 机器间channel连接
https://blog.csdn.net/KIDGIN7439/article/details/128144057
上节中完成了单机内部的channel搜索，仍然以ringGraph为例的话，相当于在单台机器内部搜索出来了一系列的环，接下来需要将机器之间的环连接起来。
为了方便理解假设两机十六卡的情况下第一台机器的一个ring为：
graph->intra: GPU/0 GPU/7 GPU/6 GPU/3 GPU/2 GPU/5 GPU/4 GPU/1
graph->inter: NET/0 NET/0
第二个机器对应的ring为：
graph->intra: GPU/10 GPU/9 GPU/8 GPU/13 GPU/12 GPU/15 GPU/14 GPU/11
graph->inter: NET/0 NET/0


NVIDIA NCCL 源码学习（六）- channel搜索
https://zhuanlan.zhihu.com/p/653440728
==上节讲到已经计算出GPU和NIC节点到其他任意节点的最优路径了，本节看下NCCL中channel的搜索过程。
nccl中channel的概念表示一个通信路径，为了更好的利用带宽和网卡，以及同一块数据可以通过多个channel并发通信，
另外后续可以看到一个channel对应了一个GPU SM， 所以基于这些原因，nccl会使用多channel，搜索的过程就是搜索出来一组channel。
如上节所述，单机的情况下会在ncclTopoTrimSystem函数里删除网卡，
因此我们先看下单机八卡这种简化的情况，最后再看下多机引入网卡之后的情况。
总结一下，本节就是基于机器拓扑，搜索出一组channel用于数据的通信，并记录到ncclTopoGraph。

NVIDIA NCCL 源码学习（五）- 路径计算
https://my.oschina.net/oneflow/blog/10089670
https://blog.csdn.net/kidgin7439/article/details/127849771
上节NCCL完成了对机器PCI系统拓扑的建图，其中建好的图如下所示，其中GPU之间是通过NVLink连接起来的
003-001.png
为了方便之后的搜索channel，接下来NCCL会先计算GPU和NIC节点到其他任意节点之间的最优路径，
以及对应的带宽，即最优路径上所有边的带宽的最小值。
那么抽象一下，这个问题可以建模为给定一个无向图，每条边有一个权值，给定查询(u, v)，求节点u到节点v的路径，
使得路径上的最小边的权值最大，类似无向图的最小瓶颈路，可以用生成树+LCA的方法解决；如果查询中的u是固定的，
那么也可以使用类似SPFA的方法解决，将松弛方法改一下即可。


NVIDIA NCCL 源码学习（四）- 建图过程
https://zhuanlan.zhihu.com/p/640812018
==上次分析了NCCL对机器PCI系统进行拓扑分析的过程，产出的结果为xml格式，
接下来，NCCL会根据这个xml进图的建立过程以便之后进行路径搜索。
总结下，由于拓扑分析产出的xml不便于进行后续的路径搜索，所以本节基于xml对PCI系统进行了建图。

NVIDIA NCCL 源码学习（三）- 机器内拓扑分析
https://zhuanlan.zhihu.com/p/625606436
==上节介绍所有节点执行了bootstrap网络连接的建立，接下来介绍下拓扑分析。
==由于GPU机器架构是多种多样的，一台机器上可能有多个网卡，多个GPU卡，卡间连接也各不相同，
==因此需要对机器内设备连接拓扑进行分析，以使性能在各种拓扑结构下都尽可能好

在看具体拓扑分析流程之前先简单了解一下PCIe的一些概念，一个简单的PCIe系统示例如下。
002-001.png
switch的作用是扩展PCIe端口，下边可以连接设备或者其他switch，上游来的请求被被他转发，
PCIe设备可以连在RC，也可以连在swtich，一个switch的内部如下所示。
002-002.png
内部有一个PCIe总线 ，然后通过多个Bridge扩展出多个端口，其中上边的那个称为上游端口，其他的叫做下游端口。
前文有提到NCCL中很常用的一个变量名叫busId，比如gpu和ib网卡，
注意区分NCCL里的busId并不是指的总线号，指的其实是定位一个PCIe设备用到的id，
即BDF(bus + device + function)，一个bus上有多个设备，一个设备有多个功能，
因此通过BDF就可以定位一个设备，
在机器启动完成PCIe的配置之后会将相关信息通过sysfs提供给用户，
NCCL就是通过sysfs来完成拓扑检测的。

总结一下，本节主要介绍了NCCL拓扑分析的过程，通过sysfs将gpu和网卡对应的pci树结构建立出来了xml树。

NVIDIA NCCL 源码学习（二）- bootstrap网络连接的建立
https://zhuanlan.zhihu.com/p/620499558
==所有节点间bootstrap的连接是如何建立的

NVIDIA NCCL 源码学习（一）- 初始化及ncclUniqueId的产生
https://zhuanlan.zhihu.com/p/614746112
==介绍到rank0的机器生成了ncclUniqueId，并完成了机器的bootstrap网络和通信网络的初始化