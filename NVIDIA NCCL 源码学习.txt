https://blog.csdn.net/kidgin7439/category_11998768.html  和知乎同名的
NVIDIA NCCL 源码学习（十）- 多机间ncclSend和ncclRecv的过程
https://blog.csdn.net/KIDGIN7439/article/details/130936177
回忆一下单机的执行流程，用户执行ncclSend之后通过ncclEnqueueCheck将sendbuff，sendbytes，peer等信息保存到了comm->p2plist中；
然后执行ncclGroupEnd，如果发现channel没有建立到peer的链接则先建链，
然后根据p2plist执行scheduleSendRecv(ncclSaveKernel)将信息保存到channel->collectives，
然后再启动kernel，kernel会遍历channel->collectives执行send和recv。然后我们看下多机的流程是怎样的。
最后总结下多机通信的整体流程
通信由kernel和proxy线程协调完成，send端kernel负责将数据从input搬运到buf，proxy线程负责将buf中数据通过网络发送给recv端
kernel和proxy间通过队列实现生产者消费者模式
send端通过rdma send发送数据，和recv端通过队列实现生产者消费者模式，队列位于send端，recv端每次下发一个wr到rq之后会执行rdma write通知send端

NVIDIA NCCL 源码学习（九）- 单机内ncclSend和ncclRecv的过程
https://blog.csdn.net/KIDGIN7439/article/details/128326053
单机内的通信都是通过kernel来进行的，所以整个通信的过程可以分为两步，第一步是准备kernel相关的参数，第二步是实际执行kernel的过程。

NVIDIA NCCL 源码学习（八）- 数据通信链路transport的建立
https://blog.csdn.net/kidgin7439/article/details/126953432
最后简单总结下，建链的过程都是以下过程：
接收端 执行recv setup，创建buffer等，将相关信息记录到connectIndo，启动一个监听socket，ip port同样记录到connectInfo，通过bootstrap发送connectInfo到 发送端。
发送端 执行send setup，创建buffer等，将相关信息记录到connectInfo，然后发送给 接收端。这一步rdma场景没有用到connectInfo。
发送端 接受到步骤1中 接收端 的信息，然后建立 发送端 到 接收端 的链接，p2p场景的话只是简单记录对端buffer，rdma场景的话需要初始化qp到INIT状态。
接收端 接受到步骤2中send发送的信息，然后建立 接收端 到 发送端 的链接，p2p场景还是记录对端buffer，rdma场景需要初始化qp到RTS状态，将本端的qp信息发送回对端。
如果rdma场景的话，发送端 还需接收对端的qp状态初始化本端的qp到RTS状态。

NVIDIA NCCL 源码学习（七）- 机器间channel连接
https://blog.csdn.net/KIDGIN7439/article/details/128144057
NVIDIA NCCL 源码学习（六）- channel搜索
https://zhuanlan.zhihu.com/p/653440728
NVIDIA NCCL 源码学习（五）- 路径计算
https://my.oschina.net/oneflow/blog/10089670
NVIDIA NCCL 源码学习（四）- 建图过程
https://zhuanlan.zhihu.com/p/640812018

NVIDIA NCCL 源码学习（三）- 机器内拓扑分析
https://zhuanlan.zhihu.com/p/625606436
==上节介绍所有节点执行了bootstrap网络连接的建立，接下来介绍下拓扑分析。
==由于GPU机器架构是多种多样的，一台机器上可能有多个网卡，多个GPU卡，卡间连接也各不相同，
==因此需要对机器内设备连接拓扑进行分析，以使性能在各种拓扑结构下都尽可能好

在看具体拓扑分析流程之前先简单了解一下PCIe的一些概念，一个简单的PCIe系统示例如下。
002-001.png
switch的作用是扩展PCIe端口，下边可以连接设备或者其他switch，上游来的请求被被他转发，
PCIe设备可以连在RC，也可以连在swtich，一个switch的内部如下所示。
002-002.png
内部有一个PCIe总线 ，然后通过多个Bridge扩展出多个端口，其中上边的那个称为上游端口，其他的叫做下游端口。
前文有提到NCCL中很常用的一个变量名叫busId，比如gpu和ib网卡，
注意区分NCCL里的busId并不是指的总线号，指的其实是定位一个PCIe设备用到的id，
即BDF(bus + device + function)，一个bus上有多个设备，一个设备有多个功能，
因此通过BDF就可以定位一个设备，
在机器启动完成PCIe的配置之后会将相关信息通过sysfs提供给用户，
NCCL就是通过sysfs来完成拓扑检测的。

总结一下，本节主要介绍了NCCL拓扑分析的过程，通过sysfs将gpu和网卡对应的pci树结构建立出来了xml树。

NVIDIA NCCL 源码学习（二）- bootstrap网络连接的建立
https://zhuanlan.zhihu.com/p/620499558
==所有节点间bootstrap的连接是如何建立的

NVIDIA NCCL 源码学习（一）- 初始化及ncclUniqueId的产生
https://zhuanlan.zhihu.com/p/614746112
==介绍到rank0的机器生成了ncclUniqueId，并完成了机器的bootstrap网络和通信网络的初始化