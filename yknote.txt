NCCL 资料
NCCL官方说明：
https://devblogs.nvidia.com/fast-multi-gpu-collectives-nccl/
https://developer.nvidia.com/nccl
http://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/index.html

https://blog.csdn.net/litdaguang/article/details/55259389
Fast Multi-GPU collectives with NCCL-翻译


yk:
NCCL_API 修饰的都是向外提供的API

https://zhuanlan.zhihu.com/p/337549503
分布式训练与NCCL


https://zhuanlan.zhihu.com/p/465967735
分布式训练硬核技术——通信原语  ==纯理论

https://zhuanlan.zhihu.com/p/609121884
【微软】MSCCL Github仓库介绍
https://github.com/Mellanox/nccl-rdma-sharp-plugins
nccl-rdma-sharp plugin enables RDMA and Switch based collectives(SHARP) with NVIDIA's NCCL library
https://docs.nvidia.com/networking/display/HPCXv27/NCCL-RDMA-SHARP+Plugins

AMD的对应 https://github.com/ROCmSoftwarePlatform/rccl

=======================================================================================================================================================

https://blog.csdn.net/weixin_34313182/article/details/92119606
nvidia-nccl 学习笔记
NCCL1 vs NCCL2
nccl1：
nccl1支持单机多卡通信，不支持多机通信。
开源地址：https://github.com/NVIDIA/nccl-tests
nccl2:
nccl2支持多机通信，在nccl1的基础上增加了多机通信策略。多机通信可进行通信协议的选择，支持通过IB、TCP等协议实现多机间数据通信。
NCCL2接口
NCCL 动态扩展
单机多卡多线程动态扩展
设计思路：
采用在线程内各自初始化自己communicator的方法进行初始化（在主线程中创建ncclid，该ncclid对全局线程可见）。当某一个线程调用merge操作失败时，查看是否因为某个线程退出引起的。
如果因为某个线程退出引起merge失败，这时每个线程重新初始化自己的communicator，并进行上一步的merge操作（该次初始化时device已经减少，相当于重新创建communicator）

测试结论：
1. 每个线程初始化自己OK
2. merge操作过程中如果出现某个线程退出，其他线程会处于block状态（不返回）
结论
单机多卡（多线程）动态扩展无法支持。
单机/多机多卡多进程动态扩展
设计思路：
采用在进程内各自初始化自己communicator的方法进行初始化（初始化时，0号进程使用tpc协议广播ncclid到全部进程）。当某一个进程调用merge操作失败时，查看是否是因为有进程退出引起的。 如果因为某个进程退出引起merge失败，这时每个进程重新初始化自己的communicator，并进行上一步的merge操作（该次初始化时device已经减少，相当于重新创建communicator）

测试结论： 1. server进程（TCP server端）创建ncclId，并且将该进程bcast到所有work进程（TCP client端），然后进行通信是可以的（server进程可以不参与通信）
2. merge操作过程中如果出现某个进程退出，其他进程全部处于block状态（不返回），且这时候其他进程的GPU使用率是100%，cpu使用100%。
结论
单机／多机多卡多进程动态扩展无法支持。


=======================================================================================================================================================

https://zhuanlan.zhihu.com/p/79030485  腾讯机智团队分享--AllReduce算法的前世今生
2019年上半年NCCL2.4提出double binary tree算法
其主要思想是利用二叉树中大约一半节点是叶子节点的特性，通过将叶子节点变换为非叶子节点，得到两颗二叉树，每个节点在其中一颗二叉树上是叶子节点，在另一颗二叉树上是非叶子节点。
这种方法理论上是能够提供比ring算法更低的延迟（log2N < N），但实际效果需要测试。后续机智团队在资源条件合适的情况下会安排进行对比。


https://lgd.gd/2021/03/21/NCCL%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/
NCCL源码阅读笔记

NCCL相关笔记
https://blog.csdn.net/eternal963/article/details/130754512?ops_request_misc=&request_id=&biz_id=102&utm_term=NCCL&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-130754512.nonecase&spm=1018.2226.3001.4449

NCCL、OpenMPI、Gloo对比
https://blog.csdn.net/taoqick/article/details/126449935?ops_request_misc=&request_id=&biz_id=102&utm_term=NCCL&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-7-126449935.nonecase&spm=1018.2226.3001.4449



PS C:\yk_repo\NCCL\v1.3.4-1> git tag
inc_nsteps_v2.16
v1.2.1-1+cuda7.5
v1.2.1-1+cuda7.5-1
v1.2.1-1+cuda8.0
v1.2.1-1+cuda8.0-1
v1.2.1-2+cuda7.5
v1.2.2-1+cuda7.5
v1.2.2-1+cuda8.0
v1.2.3-1+cuda7.5
v1.2.3-1+cuda8.0
v1.3.0-1
v1.3.4-1
v2.10.3-1
v2.11.4-1
v2.12.10-1
v2.12.12-1
v2.12.7-1
v2.13.4-1
v2.14.3-1
v2.15.1-1
v2.15.5-1
v2.16.2-1
v2.16.5-1
v2.17.1-1
v2.18.1-1
v2.18.3-1
v2.18.5-1
v2.3.5-5
v2.3.7-1
v2.4.2-1
v2.4.6-1
v2.4.7-1
v2.4.8-1
v2.5.6-1
v2.5.6-2
v2.5.7-1
v2.6.4-1
v2.7.3-1
v2.7.5-1
v2.7.6-1
v2.7.8-1
v2.8.3-1
v2.8.4-1
v2.9.6-1
v2.9.8-1
v2.9.9-1
PS C:\yk_repo


ncclResult_t ncclSaveKer  最后出现的版本是 v2.8.4-1

bootstrapNetGetSocketAddr
最先出现的版本是 v2.4.8-1(没有出现在v2.4.7-1)
最后出现的版本是 v2.7.8-1(没有出现在v2.8.3-1)
